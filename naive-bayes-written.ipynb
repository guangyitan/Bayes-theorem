{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed functions\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "from math import e\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file and retun as a list of list\n",
    "def load_csv(filename):\n",
    "\tcount = 0\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r', encoding=\"utf8\") as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\t# remove column names (Gender,Emotion_Joy,Emotion_Sadness,Emotion_Anger,Emotion_Disgust,Emotion_Fear,Emotion_Surprise,Emotion_Contempt,Emotion_Neutral,Depression)\n",
    "\t\t\tif count == 0:\n",
    "\t\t\t\tcount = 1\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "def convert_categorical_to_numerical(dataset):\n",
    "\t'''\n",
    "\tConverts categorical value to numerical\n",
    "\n",
    "\tReturns\n",
    "\tdataset (list) : list of list of dataset where categorical values are converted into numerical values\n",
    "\t'''\n",
    "\tfor row in dataset:\n",
    "\t\t# Female->0, Male->1\n",
    "\t\tif row[0] == \"Female\":\n",
    "\t\t\trow[0] = 0\n",
    "\t\telse:\n",
    "\t\t\trow[0] = 1\n",
    "\t\t\n",
    "\t\t# No->0, Yes-> 1\n",
    "\t\tif row[-1] == \"NO\":\n",
    "\t\t\trow[-1] = 0\n",
    "\t\telse:\n",
    "\t\t\trow[-1] = 1\n",
    "\treturn dataset\n",
    "\n",
    "def convert_string_to_int(dataset):\n",
    "\t'''\n",
    "\tConverts string type to int type\n",
    "\n",
    "\tReturns\n",
    "\tdataset (list) : list of list of dataset where all values are int type\n",
    "\t'''\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)):\n",
    "\t\t\t# if value is int type, continue\n",
    "\t\t\tif isinstance(row[i], int):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# else, cast value to int type\n",
    "\t\t\telse:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\trow[i] = int(row[i])\n",
    "\t\t\t\texcept ValueError:\n",
    "\t\t\t\t\tcontinue\n",
    "\treturn dataset\n",
    "\n",
    "def split_data_by_labels(dataset):\n",
    "\t'''\n",
    "\tSplit the dataset by class labels\n",
    "\n",
    "\tReturns\n",
    "\tlabels_list (list) : list of distinct labels in the dataset\n",
    "\t\teg: [0, 1] \n",
    "\t\t- there are two different labels found in the dataset\n",
    "\n",
    "\tseperated_dataset (list) : list of list of seperated dataset\n",
    "\t\teg: [[[0, 4, 3, 2],[0, 8, 0, 2],[1, 6, 2, 3]], [[1, 3, 2, 1],[0, 6, 3, 2],[0, 6, 1, 0]]] \n",
    "\t\t- a list with length of 2 is returned where each element corresponds to the row value of the respective labels\n",
    "\t'''\n",
    "\tlabels_list = []\n",
    "\tseperated_dataset = []\n",
    "\n",
    "\tfor row in dataset:\n",
    "\t\t# get the label value of the row, assume that the label value is always the last column of the dataset\n",
    "\t\tlabel_value = row[-1]\n",
    "\t\t# check if label value has been stored into labels_list\n",
    "\t\tif label_value not in labels_list:\n",
    "\t\t\t# append new label value to labels_list\n",
    "\t\t\tlabels_list.append(label_value)\n",
    "\t\t\t# append new empty list to seperated_dataset and add the row data into the new list\n",
    "\t\t\tseperated_dataset.append([])\n",
    "\t\t\tseperated_dataset[-1].append(row[:-1])\n",
    "\t\telse:\n",
    "\t\t\t# get index of corresponding label value\n",
    "\t\t\tindex = labels_list.index(row[-1])\n",
    "\t\t\t# append the row to seperated_dataset of the index \n",
    "\t\t\tseperated_dataset[index].append(row[:-1])\n",
    "\n",
    "\treturn labels_list, seperated_dataset\n",
    "\n",
    "def calculate_mean(list_numbers):\n",
    "\t'''\n",
    "\tCalculate the mean value from a list of numbers\n",
    "\n",
    "\tReturns\n",
    "\tmean (float) : mean value\n",
    "\t'''\n",
    "\tsum = 0\n",
    "\t# loop through list of numbers and add them up\n",
    "\tfor num in list_numbers:\n",
    "\t\tsum += num\n",
    "\t# divide the sum by the total list_numbers count\n",
    "\tmean = sum / len(list_numbers)\n",
    "\treturn mean\n",
    " \n",
    "def calculate_standard_deviation(numbers):\n",
    "\t'''\n",
    "\tCalculate the standard deviation from a list of numbers\n",
    "\n",
    "\tReturns\n",
    "\tstandard_deviation (float) : standard deviation value\n",
    "\t'''\n",
    "\t# calculate the mean\n",
    "\tmean = calculate_mean(numbers)\n",
    "\tsum_square_difference = 0\n",
    "\t# loop through the list of numbers and add up the squared differences \n",
    "\tfor num in numbers:\n",
    "\t\tsum_square_difference += (num - mean) ** 2\n",
    "\t# clculate variance \n",
    "\tvariance = sum_square_difference / (len(numbers) - 1)\n",
    "\t# clculate standard deviation \n",
    "\tstandard_deviation = sqrt(variance)\n",
    "\treturn standard_deviation\n",
    "\n",
    "def calculate_details(seperated_dataset):\n",
    "\t'''\n",
    "\tCalculate mean, standard deviation & count by columns seperated by labels\n",
    "\n",
    "\tReturns\n",
    "\tvalue_result (list) : [mean, std_dev] list of list of mean & standard deviation calculated for each column by each labels\n",
    "\t\teg: [[[0.66, 0.47, 4],[8.72, 10.72, 4],[2.29, 3.35, 4], [[0.56, 0.50, 5],[9.12, 11.96, 5],[3.67, 3.35, 5]]]\n",
    "\t'''\n",
    "\tvalue_result = []\n",
    "\t# labels_list, seperated_dataset = split_data_by_labels(dataset) TODO: remove\n",
    "\tfor j in range(len(seperated_dataset)):\n",
    "\t\tx_list = []\n",
    "\t\tcount = 0\n",
    "\t\tfor row in seperated_dataset[j]:\n",
    "\t\t\tfor i in range(len(row)):\n",
    "\t\t\t\tif count == 0:\n",
    "\t\t\t\t\tx_list.append([])\n",
    "\t\t\t\t\tx_list[-1].append(row[i])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx_list[i].append(row[i])\n",
    "\t\t\tcount = 1\n",
    "\n",
    "\t\tcount2 = 0\n",
    "\t\tfor x_s in x_list:\n",
    "\t\t\tif count2 == 0:\n",
    "\t\t\t\tvalue_result.append([])\n",
    "\t\t\t\tcount2 = 1\n",
    "\t\t\tvalue_result[-1].append([calculate_mean(x_s), calculate_standard_deviation(x_s), len(seperated_dataset[j])])\n",
    "\treturn value_result\n",
    "\n",
    "def calculate_gaussian_probability(x, mean, std_dev):\n",
    "\t'''\n",
    "\tCalculate Gaussian Probability of x\n",
    "\n",
    "\tReturns\n",
    "\tgaussian_probability (float) : Gaussian Probability of x\n",
    "\t'''\n",
    "\tlhs = 1 / (std_dev * sqrt(2 * pi))\n",
    "\texponent = -(1 / 2) * ((x - mean) / std_dev) ** 2 \n",
    "\tgaussian_probability = lhs * (e ** exponent) \n",
    "\treturn gaussian_probability\n",
    "\n",
    "def calculate_probabilities_by_class(row, labels_list, dataset_details):\n",
    "\t'''\n",
    "\tCalculate Probability of a row for each labels\n",
    "\n",
    "\tReturns\n",
    "\tprobabilities_list (list) : list of probabilities for each labels\n",
    "\t'''\n",
    "\tprobabilities_list = []\n",
    "\tfor i in range(len(labels_list)):\n",
    "\t\tprobability = dataset_details[i][0][-1] / sum([dataset_details[k][0][-1] for k in range(len(dataset_details))]) \n",
    "\n",
    "\t\tfor j in range(len(row)):\n",
    "\t\t\tprobability *= calculate_gaussian_probability(row[j], dataset_details[i][j][0], dataset_details[i][j][1])\n",
    "\t\tprobabilities_list.append(probability)\n",
    "\treturn probabilities_list\n",
    "\n",
    "# TODO: add param to comments\n",
    "def predict(row, labels_list, dataset_details):\n",
    "\t'''\n",
    "\tPredict the label for a given row.\n",
    "\t    \n",
    "\tReturns \n",
    "\tpredicted_label (int) : the integer value representing the label with the highest probability\n",
    "\t'''\n",
    "\tprobabilities_list = calculate_probabilities_by_class(row, labels_list, dataset_details)\n",
    "\tprediction = -1\n",
    "\tpredicted_label = -1\n",
    "\t# loop through probability calculated for each label\n",
    "\tfor i in range(len(probabilities_list)):\n",
    "\t\t# get the label with the highest probability value\n",
    "\t\tif probabilities_list[i] > prediction:\n",
    "\t\t\tprediction = probabilities_list[i]\n",
    "\t\t\tpredicted_label = labels_list[i]\n",
    "\treturn predicted_label\n",
    "\n",
    "def predict_all(dataset_without_labels, labels_list, dataset_details):\n",
    "\t''' \n",
    "\tPredict all labels for dataset using Naive Bayes classification algorithm.\n",
    "\n",
    "\tReturns\n",
    "\tpredicted_labels (list) : the list of predicted labels\n",
    "\t'''\n",
    "\tpredicted_labels = []\n",
    "\tfor row in dataset_without_labels:\n",
    "\t\tpredicted_label = predict(row, labels_list, dataset_details)\n",
    "\t\tpredicted_labels.append(predicted_label)\n",
    "\treturn predicted_labels\n",
    "\n",
    "def calculate_accuracy(predicted_labels, actual_labels):\n",
    "\t'''\n",
    "\tCalculate the accuracy based on the predicted labels\n",
    "\n",
    "\tReturns\n",
    "\taccuracy (int) : the accuracy\n",
    "\t'''\n",
    "\tcorrect_count = 0\n",
    "\t# loop through predicted and actual labels\n",
    "\tfor predicted, actual in zip(predicted_labels, actual_labels):\n",
    "\t\t# if predicted label equals the actual label\n",
    "\t\tif predicted == actual:\n",
    "\t\t\tcorrect_count += 1\n",
    "\t# calculate accuracy\n",
    "\taccuracy = correct_count / len(predicted_labels)\n",
    "\treturn accuracy\n",
    "\n",
    "def zeroR(dataset, labels_list):\n",
    "\t'''\n",
    "\tPredict all labels for dataset using ZeroR classification algorithm.\n",
    "\n",
    "\tReturns\n",
    "\tpredicted_labels (list) : the list of predicted labels\n",
    "\t'''\n",
    "\t# initialize a list of 0 that has the same length as all possible labels to store total count of each labels in the dataset\n",
    "\tlabel_count_list = [0] * len(labels_list)\n",
    "\n",
    "\t#loop through each row in the dataset\n",
    "\tfor row in dataset:\n",
    "\t\t# loop through each label in the labels_list\n",
    "\t\tfor i in range(len(labels_list)):\n",
    "\t\t\t# check if the actual label of the row is equal to the label of the labels_list\n",
    "\t\t\tif row[-1] == labels_list[i]:\n",
    "\t\t\t\t# add the count of the label in the label_count_list\n",
    "\t\t\t\tlabel_count_list[i] +=1\n",
    "\n",
    "\t# loop through the label_count_list to find the most frequent label in the dataset\n",
    "\tmost_frequent_label = -1\n",
    "\tmost_frequent_label_count = -1\n",
    "\tfor i in range(len(label_count_list)):\n",
    "\t\t# if the count of current label is greater than the highest label count\n",
    "\t\tif label_count_list[i] > most_frequent_label_count:\n",
    "\t\t\tmost_frequent_label_count = label_count_list[i]\n",
    "\t\t\t# set highest label count as the current label\n",
    "\t\t\tmost_frequent_label = labels_list[i]\n",
    "\n",
    "\tprint(\"label_count_list: \", label_count_list)\n",
    "\tprint(\"most_frequent_label: \", most_frequent_label)\n",
    "\tpredicted_labels = [most_frequent_label] * len(dataset)\n",
    "\treturn predicted_labels\n",
    "\n",
    "def build_frequency_table(column_value_list, labels):\n",
    "\t''' \n",
    "\tCount the frequency of each label for each column value\n",
    "\n",
    "\tReturns\n",
    "\tfrequency_table (dict of dict) : dictionary with column value as key and frequency count of each lables \n",
    "\t\teg: {2: {0: 5, 1: 9}, 0: {0: 27, 1: 21}, 5: {1: 1}}\n",
    "\t'''\n",
    "\t# Count the frequency of each class label for each feature value\n",
    "\tfrequency_table = {}\n",
    "\tfor feature_value, label in zip(column_value_list, labels):\n",
    "\t\tif feature_value not in frequency_table:\n",
    "\t\t\tfrequency_table[feature_value] = {}\n",
    "\t\tif label not in frequency_table[feature_value]:\n",
    "\t\t\tfrequency_table[feature_value][label] = 0\n",
    "\t\tfrequency_table[feature_value][label] += 1\n",
    "\n",
    "\treturn frequency_table\n",
    "\n",
    "def calculate_error(column_value_list, labels):\n",
    "\t\"\"\"\n",
    "\tCalculate the error rate for a given feature and label pair.\n",
    "\n",
    "\tParameters: TODO: remove\n",
    "\t\tcolumn_value_list (list): A list of feature values.\n",
    "\t\tlabels (list): A list of corresponding class labels.\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t\tThe error rate for this feature.\n",
    "\t\"\"\"\n",
    "\n",
    "\tfrequency_table = build_frequency_table(column_value_list, labels)\n",
    "\t# # Count the frequency of each class label for each feature value\n",
    "\t# frequency_table = {}\n",
    "\t# for feature_value, label in zip(column_value_list, labels):\n",
    "\t# \tif feature_value not in frequency_table:\n",
    "\t# \t\tfrequency_table[feature_value] = {}\n",
    "\t# \tif label not in frequency_table[feature_value]:\n",
    "\t# \t\tfrequency_table[feature_value][label] = 0\n",
    "\t# \tfrequency_table[feature_value][label] += 1\n",
    "\n",
    "\t# Calculate the total number of samples\n",
    "\ttotal_samples = len(column_value_list)\n",
    "\ttotal_errors = 0\n",
    "\t# loop through each column value \n",
    "\tfor feature_value, label_counts in frequency_table.items():\n",
    "\t\t# label_counts is the inner dictoray for the occurence frequency for each labels\n",
    "\t\t# get the label with higest count for this column\n",
    "\t\thigest_count_label = max(label_counts, key=label_counts.get)\n",
    "\t\terror_count = sum(label_counts.values()) - label_counts[higest_count_label]\n",
    "\t\ttotal_errors += error_count\n",
    "\n",
    "    # Return the error rate\n",
    "\treturn total_errors / total_samples\n",
    "\n",
    "def oneR_predict(column_value, best_predictor_frequency_table):\n",
    "\t'''\n",
    "\treturn predicted label based on the best predictor\n",
    "\n",
    "\tReturns\n",
    "\t\tpredicted_label (int) : predicted label\n",
    "\t'''\n",
    "\tcolumn_value_dict = best_predictor_frequency_table[column_value]\n",
    "\tpredicted_label = max(column_value_dict, key=column_value_dict.get)\n",
    "\n",
    "\treturn predicted_label\n",
    "\n",
    "def OneR_classification(dataset_without_labels, train_labels):\n",
    "\t\"\"\"\n",
    "\tImplements the OneR classification algorithm, which selects a single feature to make predictions.\n",
    "\n",
    "\tParameters:  TODO: remove\n",
    "\t\ttrain_features (list of lists): A list of training samples, where each sample is a list of feature values.\n",
    "\t\ttrain_labels (list): A list of labels from the training set.\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t\tpredicted_labels (list) : the list of predicted labels\n",
    "\t\"\"\"\n",
    "\t# Find the best feature by calculating the error rate for each feature\n",
    "\tbest_predictor_index = None\n",
    "\tlowest_error_rate = 9999\n",
    "\t# loop though each column\n",
    "\tfor column_index in range(len(dataset_without_labels[0])):\n",
    "\t\t# get a list of all values in a column\n",
    "\t\tcolumn_values = [row[column_index] for row in dataset_without_labels]\n",
    "\t\terror_rate = calculate_error(column_values, train_labels)\n",
    "\t\t# get the lowest error rate \n",
    "\t\tif error_rate < lowest_error_rate:\n",
    "\t\t\tbest_predictor_index = column_index\n",
    "\t\t\tlowest_error_rate = error_rate\n",
    "\n",
    "\t# get the column values of the best predictor\n",
    "\tbest_predictor_column_values = [row[best_predictor_index] for row in dataset_without_labels]\n",
    "\t# get the frequency table of the best predictor\n",
    "\tbest_predictor_frequency_table =  build_frequency_table(best_predictor_column_values, train_labels)\n",
    "\n",
    "\t# predict the labels by using the best predictor\n",
    "\tpredicted_labels = []\n",
    "\tfor column_value in best_predictor_column_values:\n",
    "\t\tpredicted_label = oneR_predict(column_value, best_predictor_frequency_table)\n",
    "\t\tpredicted_labels.append(predicted_label)\n",
    "\n",
    "\treturn predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_count_list:  [48, 52]\n",
      "most_frequent_label:  1\n",
      "accuracy_naive_bayes:  0.58\n",
      "accuracy_zeroR:  0.52\n",
      "accuracy_oneR:  0.68\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_csv(\"dataset.csv\")\n",
    "dataset = convert_categorical_to_numerical(dataset)\n",
    "dataset = convert_string_to_int(dataset)\n",
    "labels_list, seperated_dataset = split_data_by_labels(dataset)\n",
    "dataset_details = calculate_details(seperated_dataset)\n",
    "\n",
    "# predict one row of data only\n",
    "predicted_label = predict(dataset[0][:-1], labels_list, dataset_details)\n",
    "\n",
    "# get dataset without the labels\n",
    "dataset_without_labels = [row[:-1] for row in dataset]\n",
    "# get a list of actual labels of the dataset\n",
    "actual_labels = [row[-1] for row in dataset]\n",
    "\n",
    "# predict the labels with Naive Bayes classification algorithm\n",
    "predicted_labels_naive_bayes = predict_all(dataset_without_labels, labels_list, dataset_details)\n",
    "# predict the labels with ZeroR classification algorithm\n",
    "predicted_labels_zeroR = zeroR(dataset, labels_list)\n",
    "# predict the labels with OneR classification algorithm\n",
    "predicted_labels_oneR = OneR_classification(dataset_without_labels, actual_labels)\n",
    "\n",
    "# calculate accuracy of each classification algorithm\n",
    "accuracy_naive_bayes = calculate_accuracy(predicted_labels_naive_bayes, actual_labels)\n",
    "accuracy_zeroR = calculate_accuracy(predicted_labels_zeroR, actual_labels)\n",
    "accuracy_oneR = calculate_accuracy(predicted_labels_oneR, actual_labels)\n",
    "print(\"accuracy_naive_bayes: \", accuracy_naive_bayes)\n",
    "print(\"accuracy_zeroR: \", accuracy_zeroR)\n",
    "print(\"accuracy_oneR: \", accuracy_oneR)\n",
    "print(predicted_labels_naive_bayes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset = load_csv(\"dataset.csv\")\n",
    "dataset = convert_categorical_to_numerical(dataset)\n",
    "dataset = convert_string_to_int(dataset)\n",
    "dataset_without_labels = [row[:-1] for row in dataset]\n",
    "# get a list of actual labels of the dataset\n",
    "actual_labels = [row[-1] for row in dataset]\n",
    "\n",
    "# create an instance of the StandardScaler class\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the data and transform it\n",
    "dataset_without_labels_scaled = scaler.fit_transform(dataset_without_labels)\n",
    "dataset_without_labels_scaled = dataset_without_labels_scaled.tolist()\n",
    "\n",
    "dataset_with_labels_scaled = []\n",
    "for i in range(len(dataset_without_labels_scaled)):\n",
    "    temp_row = dataset_without_labels_scaled[i].copy()\n",
    "    temp_row.append(actual_labels[i])\n",
    "    dataset_with_labels_scaled.append(temp_row)\n",
    "\n",
    "labels_list, seperated_dataset_scaled = split_data_by_labels(dataset_with_labels_scaled)\n",
    "dataset_details_scaled = calculate_details(seperated_dataset_scaled)\n",
    "\n",
    "# predict the labels with Naive Bayes classification algorithm\n",
    "predicted_labels_naive_bayes_scaled = predict_all(dataset_without_labels_scaled, labels_list, dataset_details_scaled)\n",
    "# calculate accuracy of each classification algorithm\n",
    "accuracy_naive_bayes_scaled = calculate_accuracy(predicted_labels_naive_bayes_scaled, actual_labels)\n",
    "print(accuracy_naive_bayes_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset = load_csv(\"dataset.csv\")\n",
    "dataset = convert_categorical_to_numerical(dataset)\n",
    "dataset = convert_string_to_int(dataset)\n",
    "dataset_without_labels = [row[:-1] for row in dataset]\n",
    "# get a list of actual labels of the dataset\n",
    "actual_labels = [row[-1] for row in dataset]\n",
    "\n",
    "# create an instance of the StandardScaler class\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit the scaler to the data and transform it\n",
    "dataset_without_labels_scaled = scaler.fit_transform(dataset_without_labels)\n",
    "dataset_without_labels_scaled = dataset_without_labels_scaled.tolist()\n",
    "\n",
    "dataset_with_labels_scaled = []\n",
    "for i in range(len(dataset_without_labels_scaled)):\n",
    "    temp_row = dataset_without_labels_scaled[i].copy()\n",
    "    temp_row.append(actual_labels[i])\n",
    "    dataset_with_labels_scaled.append(temp_row)\n",
    "\n",
    "labels_list, seperated_dataset_scaled = split_data_by_labels(dataset_with_labels_scaled)\n",
    "dataset_details_scaled = calculate_details(seperated_dataset_scaled)\n",
    "\n",
    "# predict the labels with Naive Bayes classification algorithm\n",
    "predicted_labels_naive_bayes_scaled = predict_all(dataset_without_labels_scaled, labels_list, dataset_details_scaled)\n",
    "# calculate accuracy of each classification algorithm\n",
    "accuracy_naive_bayes_scaled = calculate_accuracy(predicted_labels_naive_bayes_scaled, actual_labels)\n",
    "print(accuracy_naive_bayes_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.6666666666666666, 0.47639306734033077, 48], [0.09093137254901956, 0.12612131724931921, 48], [0.10416666666666667, 0.15233899171176235, 48], [0.234375, 0.252151645102029, 48], [0.10677083333333333, 0.13883439385987795, 48], [0.10984848484848485, 0.15345311234094494, 48], [0.18489583333333334, 0.15893090156301007, 48], [0.1128472222222222, 0.1839364542126907, 48], [0.028617216117216113, 0.02355676282006951, 48]], [[0.5576923076923077, 0.5015060275070906, 52], [0.09547511312217191, 0.1406498028172087, 52], [0.16695804195804193, 0.1524182941768658, 52], [0.3389423076923077, 0.30652277614006007, 52], [0.18990384615384615, 0.21507292512580922, 52], [0.16258741258741263, 0.20885171039410946, 52], [0.23557692307692307, 0.23698195067812577, 52], [0.15705128205128208, 0.19571516122629867, 52], [0.054628064243448855, 0.13712504106303772, 52]]]\n",
      "[[[0.6666666666666666, 0.47639306734033077, 48], [8.729166666666666, 10.720311966192133, 48], [2.2916666666666665, 3.3514578176587717, 48], [1.875, 2.017213160816232, 48], [0.8541666666666666, 1.1106751508790236, 48], [2.4166666666666665, 3.3759684715007894, 48], [1.4791666666666667, 1.2714472125040805, 48], [1.3541666666666667, 2.2072374505522894, 48], [5.208333333333333, 4.287330833252652, 48]], [[0.5576923076923077, 0.5015060275070906, 52], [9.115384615384615, 11.95523323946274, 52], [3.673076923076923, 3.353202471891047, 52], [2.7115384615384617, 2.4521822091204806, 52], [1.5192307692307692, 1.7205834010064738, 52], [3.576923076923077, 4.594737628670407, 52], [1.8846153846153846, 1.8958556054250062, 52], [1.8846153846153846, 2.3485819347155843, 52], [9.942307692307692, 24.956757473472866, 52]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_details_scaled)\n",
    "print(dataset_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.6666666666666666, 0.47639306734033077, 48],\n",
       "  [0.09093137254901956, 0.12612131724931921, 48],\n",
       "  [0.10416666666666667, 0.15233899171176235, 48],\n",
       "  [0.234375, 0.252151645102029, 48],\n",
       "  [0.10677083333333333, 0.13883439385987795, 48],\n",
       "  [0.10984848484848485, 0.15345311234094494, 48],\n",
       "  [0.18489583333333334, 0.15893090156301007, 48],\n",
       "  [0.1128472222222222, 0.1839364542126907, 48],\n",
       "  [0.028617216117216113, 0.02355676282006951, 48]],\n",
       " [[0.5576923076923077, 0.5015060275070906, 52],\n",
       "  [0.09547511312217191, 0.1406498028172087, 52],\n",
       "  [0.16695804195804193, 0.1524182941768658, 52],\n",
       "  [0.3389423076923077, 0.30652277614006007, 52],\n",
       "  [0.18990384615384615, 0.21507292512580922, 52],\n",
       "  [0.16258741258741263, 0.20885171039410946, 52],\n",
       "  [0.23557692307692307, 0.23698195067812577, 52],\n",
       "  [0.15705128205128208, 0.19571516122629867, 52],\n",
       "  [0.054628064243448855, 0.13712504106303772, 52]]]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_details_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create a numpy array\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# convert to a list\n",
    "lst = arr.tolist()\n",
    "\n",
    "print(lst)  # Output: [1, 2, 3, 4, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Using the copy() method\n",
    "old_list = [1, 2, 3]\n",
    "new_list = old_list.copy()\n",
    "new_list.append(4)\n",
    "\n",
    "print(old_list)  # Output: [1, 2, 3]\n",
    "print(new_list)  # Output: [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {0: 1}, 2: {1: 2, 0: 1}, 3: {0: 1}}\n"
     ]
    }
   ],
   "source": [
    "column_value_list = [1, 2, 3, 2,2]\n",
    "labels = [0,1,0,0, 1]\n",
    "frequency_table = {}\n",
    "for feature_value, label in zip(column_value_list, labels):\n",
    "    if feature_value not in frequency_table:\n",
    "        frequency_table[feature_value] = {}\n",
    "    if label not in frequency_table[feature_value]:\n",
    "        frequency_table[feature_value][label] = 0\n",
    "    frequency_table[feature_value][label] += 1\n",
    "\n",
    "print(frequency_table)\n",
    "# most_common_label = max(label_counts, key=label_counts.get)\n",
    "# print(most_common_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\"apple\": 2, \"banana\": 3, \"orange\": 3}\n",
    "\n",
    "max_key = max(my_dict, key=my_dict.get)\n",
    "\n",
    "print(max_key)   # Output: \"orange\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_count_list:  [5, 5]\n",
      "most_frequent_label:  0\n",
      "row:  {3.393533211: {0: 1}, 3.110073483: {0: 1}, 1.343808831: {0: 1}, 3.582294042: {0: 1}, 2.280362439: {0: 1}, 7.423436942: {1: 1}, 5.745051997: {1: 1}, 9.172168622: {1: 1}, 7.792783481: {1: 1}, 7.939820817: {1: 1}}\n",
      "error rate:  0.0\n",
      "row:  {2.331273381: {0: 1}, 1.781539638: {0: 1}, 3.368360954: {0: 1}, 4.67917911: {0: 1}, 2.866990263: {0: 1}, 4.696522875: {1: 1}, 3.533989803: {1: 1}, 2.511101045: {1: 1}, 3.424088941: {1: 1}, 0.791637231: {1: 1}}\n",
      "error rate:  0.0\n",
      "{'best_feature': 0, 'error_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test calculating class probabilities\n",
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]\n",
    "# dataset = convert_categorical_to_numerical(dataset)\n",
    "# dataset = convert_string_to_int(dataset)\n",
    "labels_list, seperated_dataset = split_data_by_labels(dataset)\n",
    "dataset_details = calculate_details(seperated_dataset)\n",
    "predicted_label = predict(dataset[0][:-1], labels_list, dataset_details)\n",
    "# use dataset[:-1] to pass in dataset without the labels\n",
    "dataset_without_labels = [row[:-1] for row in dataset]\n",
    "actual_labels = [row[-1] for row in dataset]\n",
    "predicted_labels = predict_all(dataset_without_labels, labels_list, dataset_details)\n",
    "predicted_labels_zeroR = zeroR(dataset, labels_list)\n",
    "\n",
    "oneR_result = OneR_classification(dataset_without_labels, actual_labels)\n",
    "print(oneR_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(predicted_labels_zeroR, actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.393533211, 2.331273381], [0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][:-1],[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2.85742739175, 1.0275719447560472, 4],\n",
       "  [3.04008827075, 1.275505774560249, 4]],\n",
       " [[6.725604049666667, 2.441618256572654, 6],\n",
       "  [2.9707216929999998, 1.3016622439989782, 6]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([dataset_details[k][0][-1] for k in range(len(dataset_details))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 4, 3, 2, 1, 0, 2, 2, 1, 0],\n",
       " [0, 8, 0, 2, 0, 1, 0, 0, 4, 0],\n",
       " [1, 5, 0, 0, 0, 14, 2, 0, 15, 0],\n",
       " [1, 7, 0, 3, 0, 0, 5, 0, 0, 0],\n",
       " [1, 3, 2, 1, 0, 2, 1, 0, 6, 1],\n",
       " [0, 23, 1, 1, 0, 0, 1, 1, 3, 0],\n",
       " [0, 6, 3, 2, 1, 1, 1, 1, 3, 1],\n",
       " [1, 6, 0, 2, 0, 1, 1, 0, 5, 0],\n",
       " [0, 1, 7, 3, 0, 7, 1, 0, 2, 1],\n",
       " [1, 3, 2, 2, 1, 0, 2, 2, 8, 1],\n",
       " [1, 6, 0, 3, 0, 2, 1, 2, 4, 1],\n",
       " [1, 6, 0, 1, 3, 4, 2, 7, 3, 0],\n",
       " [1, 6, 0, 1, 0, 0, 0, 3, 6, 0],\n",
       " [0, 3, 1, 0, 0, 1, 2, 3, 4, 0],\n",
       " [0, 7, 3, 5, 0, 1, 1, 0, 3, 0],\n",
       " [1, 11, 2, 0, 0, 16, 1, 1, 12, 1],\n",
       " [1, 6, 0, 0, 2, 0, 1, 0, 8, 1],\n",
       " [1, 19, 5, 8, 0, 7, 1, 0, 20, 1],\n",
       " [1, 3, 0, 1, 1, 0, 3, 0, 10, 0],\n",
       " [1, 1, 3, 1, 3, 1, 2, 2, 2, 0],\n",
       " [1, 3, 2, 1, 1, 1, 4, 1, 1, 0],\n",
       " [1, 4, 2, 1, 1, 1, 1, 1, 4, 1],\n",
       " [1, 9, 1, 3, 0, 2, 1, 4, 2, 1],\n",
       " [0, 5, 3, 5, 2, 1, 2, 1, 0, 1],\n",
       " [1, 7, 2, 1, 2, 1, 2, 0, 2, 1],\n",
       " [0, 9, 0, 0, 0, 0, 1, 4, 1, 0],\n",
       " [1, 6, 2, 5, 1, 3, 3, 1, 10, 1],\n",
       " [1, 18, 2, 6, 2, 4, 5, 2, 9, 0],\n",
       " [1, 25, 4, 2, 0, 7, 2, 0, 17, 0],\n",
       " [1, 10, 12, 0, 0, 2, 2, 0, 11, 1],\n",
       " [1, 19, 5, 7, 4, 8, 8, 3, 9, 1],\n",
       " [0, 8, 0, 3, 0, 0, 1, 0, 3, 0],\n",
       " [1, 6, 1, 0, 3, 1, 0, 4, 4, 1],\n",
       " [1, 26, 0, 0, 0, 13, 0, 11, 4, 0],\n",
       " [1, 4, 3, 5, 0, 2, 0, 0, 5, 0],\n",
       " [1, 8, 0, 4, 8, 0, 7, 2, 13, 1],\n",
       " [0, 24, 4, 2, 1, 0, 0, 1, 11, 1],\n",
       " [1, 6, 1, 0, 0, 0, 1, 0, 7, 0],\n",
       " [1, 3, 2, 0, 1, 6, 1, 1, 1, 0],\n",
       " [1, 2, 2, 3, 2, 0, 3, 0, 3, 0],\n",
       " [0, 10, 3, 0, 0, 6, 3, 0, 2, 0],\n",
       " [1, 5, 4, 2, 0, 3, 3, 3, 3, 1],\n",
       " [1, 2, 4, 1, 3, 1, 1, 2, 1, 1],\n",
       " [1, 12, 4, 3, 3, 4, 2, 6, 8, 1],\n",
       " [0, 9, 2, 6, 4, 0, 4, 2, 9, 1],\n",
       " [1, 1, 4, 0, 0, 0, 0, 0, 17, 0],\n",
       " [0, 8, 4, 2, 1, 2, 2, 3, 5, 1],\n",
       " [1, 6, 4, 1, 2, 0, 0, 0, 5, 1],\n",
       " [1, 11, 1, 3, 2, 3, 1, 0, 4, 0],\n",
       " [1, 6, 3, 0, 1, 2, 3, 0, 0, 1],\n",
       " [1, 6, 1, 2, 0, 3, 1, 0, 4, 0],\n",
       " [1, 3, 4, 2, 2, 1, 3, 2, 2, 0],\n",
       " [0, 1, 1, 1, 4, 0, 0, 0, 21, 1],\n",
       " [1, 4, 1, 2, 1, 2, 1, 0, 7, 1],\n",
       " [0, 6, 6, 5, 6, 3, 5, 4, 7, 1],\n",
       " [0, 6, 2, 1, 1, 1, 2, 0, 2, 1],\n",
       " [0, 5, 1, 0, 3, 2, 0, 0, 5, 0],\n",
       " [1, 8, 4, 4, 0, 2, 1, 0, 3, 0],\n",
       " [1, 10, 3, 8, 3, 5, 6, 12, 4, 1],\n",
       " [1, 9, 5, 7, 0, 2, 0, 0, 10, 0],\n",
       " [0, 6, 2, 8, 4, 8, 1, 0, 4, 0],\n",
       " [1, 10, 3, 2, 0, 2, 2, 3, 5, 0],\n",
       " [1, 11, 0, 0, 0, 3, 3, 2, 18, 1],\n",
       " [0, 2, 3, 2, 1, 4, 2, 0, 1, 1],\n",
       " [0, 6, 2, 0, 0, 1, 1, 0, 11, 0],\n",
       " [1, 71, 22, 2, 2, 12, 0, 2, 10, 0],\n",
       " [0, 6, 5, 3, 3, 2, 2, 3, 3, 0],\n",
       " [0, 14, 2, 6, 0, 4, 2, 0, 0, 0],\n",
       " [0, 7, 1, 1, 1, 1, 1, 0, 3, 0],\n",
       " [1, 4, 1, 1, 2, 3, 3, 3, 3, 0],\n",
       " [1, 9, 2, 1, 1, 3, 3, 2, 2, 1],\n",
       " [1, 10, 7, 1, 0, 0, 1, 1, 14, 0],\n",
       " [1, 2, 2, 5, 1, 1, 0, 3, 5, 1],\n",
       " [1, 6, 0, 1, 0, 4, 2, 5, 12, 1],\n",
       " [0, 9, 4, 5, 1, 3, 1, 0, 2, 1],\n",
       " [1, 7, 2, 2, 3, 2, 2, 3, 2, 1],\n",
       " [0, 2, 0, 0, 1, 0, 2, 6, 4, 0],\n",
       " [1, 6, 0, 0, 2, 0, 1, 0, 7, 0],\n",
       " [0, 1, 10, 1, 1, 7, 1, 3, 2, 1],\n",
       " [0, 12, 2, 0, 0, 3, 0, 0, 1, 1],\n",
       " [0, 17, 4, 5, 3, 1, 2, 2, 14, 1],\n",
       " [1, 11, 3, 0, 0, 1, 0, 0, 0, 1],\n",
       " [1, 20, 3, 5, 2, 5, 5, 7, 4, 1],\n",
       " [1, 8, 3, 0, 1, 2, 3, 0, 4, 0],\n",
       " [0, 7, 10, 2, 0, 22, 0, 0, 1, 1],\n",
       " [1, 5, 2, 1, 0, 1, 2, 0, 4, 1],\n",
       " [1, 6, 4, 2, 0, 1, 1, 3, 2, 0],\n",
       " [0, 6, 10, 8, 1, 10, 0, 0, 19, 1],\n",
       " [0, 8, 1, 0, 1, 0, 0, 1, 10, 0],\n",
       " [0, 7, 7, 6, 3, 6, 3, 4, 1, 1],\n",
       " [0, 86, 17, 8, 3, 20, 6, 6, 182, 1],\n",
       " [0, 6, 3, 3, 4, 6, 1, 2, 4, 1],\n",
       " [0, 2, 4, 2, 0, 1, 0, 0, 6, 1],\n",
       " [0, 4, 2, 5, 0, 1, 1, 0, 7, 1],\n",
       " [1, 7, 2, 3, 1, 1, 0, 0, 1, 0],\n",
       " [0, 10, 9, 0, 0, 2, 0, 4, 18, 1],\n",
       " [0, 6, 1, 0, 0, 3, 0, 0, 11, 1],\n",
       " [1, 4, 3, 0, 2, 0, 2, 0, 4, 0],\n",
       " [1, 2, 0, 1, 0, 2, 1, 0, 9, 0],\n",
       " [1, 6, 2, 3, 0, 2, 0, 4, 2, 0]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.6666666666666666, 0.47639306734033077, 48],\n",
       "  [8.729166666666666, 10.720311966192133, 48],\n",
       "  [2.2916666666666665, 3.3514578176587717, 48],\n",
       "  [1.875, 2.017213160816232, 48],\n",
       "  [0.8541666666666666, 1.1106751508790236, 48],\n",
       "  [2.4166666666666665, 3.3759684715007894, 48],\n",
       "  [1.4791666666666667, 1.2714472125040805, 48],\n",
       "  [1.3541666666666667, 2.2072374505522894, 48],\n",
       "  [5.208333333333333, 4.287330833252652, 48]],\n",
       " [[0.5576923076923077, 0.5015060275070906, 52],\n",
       "  [9.115384615384615, 11.95523323946274, 52],\n",
       "  [3.673076923076923, 3.353202471891047, 52],\n",
       "  [2.7115384615384617, 2.4521822091204806, 52],\n",
       "  [1.5192307692307692, 1.7205834010064738, 52],\n",
       "  [3.576923076923077, 4.594737628670407, 52],\n",
       "  [1.8846153846153846, 1.8958556054250062, 52],\n",
       "  [1.8846153846153846, 2.3485819347155843, 52],\n",
       "  [9.942307692307692, 24.956757473472866, 52]]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_details[1][0][-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 4, 3, 2, 1, 0, 2, 2, 1],\n",
       "  [0, 8, 0, 2, 0, 1, 0, 0, 4],\n",
       "  [1, 5, 0, 0, 0, 14, 2, 0, 15],\n",
       "  [1, 7, 0, 3, 0, 0, 5, 0, 0],\n",
       "  [0, 23, 1, 1, 0, 0, 1, 1, 3],\n",
       "  [1, 6, 0, 2, 0, 1, 1, 0, 5],\n",
       "  [1, 6, 0, 1, 3, 4, 2, 7, 3],\n",
       "  [1, 6, 0, 1, 0, 0, 0, 3, 6],\n",
       "  [0, 3, 1, 0, 0, 1, 2, 3, 4],\n",
       "  [0, 7, 3, 5, 0, 1, 1, 0, 3],\n",
       "  [1, 3, 0, 1, 1, 0, 3, 0, 10],\n",
       "  [1, 1, 3, 1, 3, 1, 2, 2, 2],\n",
       "  [1, 3, 2, 1, 1, 1, 4, 1, 1],\n",
       "  [0, 9, 0, 0, 0, 0, 1, 4, 1],\n",
       "  [1, 18, 2, 6, 2, 4, 5, 2, 9],\n",
       "  [1, 25, 4, 2, 0, 7, 2, 0, 17],\n",
       "  [0, 8, 0, 3, 0, 0, 1, 0, 3],\n",
       "  [1, 26, 0, 0, 0, 13, 0, 11, 4],\n",
       "  [1, 4, 3, 5, 0, 2, 0, 0, 5],\n",
       "  [1, 6, 1, 0, 0, 0, 1, 0, 7],\n",
       "  [1, 3, 2, 0, 1, 6, 1, 1, 1],\n",
       "  [1, 2, 2, 3, 2, 0, 3, 0, 3],\n",
       "  [0, 10, 3, 0, 0, 6, 3, 0, 2],\n",
       "  [1, 1, 4, 0, 0, 0, 0, 0, 17],\n",
       "  [1, 11, 1, 3, 2, 3, 1, 0, 4],\n",
       "  [1, 6, 1, 2, 0, 3, 1, 0, 4],\n",
       "  [1, 3, 4, 2, 2, 1, 3, 2, 2],\n",
       "  [0, 5, 1, 0, 3, 2, 0, 0, 5],\n",
       "  [1, 8, 4, 4, 0, 2, 1, 0, 3],\n",
       "  [1, 9, 5, 7, 0, 2, 0, 0, 10],\n",
       "  [0, 6, 2, 8, 4, 8, 1, 0, 4],\n",
       "  [1, 10, 3, 2, 0, 2, 2, 3, 5],\n",
       "  [0, 6, 2, 0, 0, 1, 1, 0, 11],\n",
       "  [1, 71, 22, 2, 2, 12, 0, 2, 10],\n",
       "  [0, 6, 5, 3, 3, 2, 2, 3, 3],\n",
       "  [0, 14, 2, 6, 0, 4, 2, 0, 0],\n",
       "  [0, 7, 1, 1, 1, 1, 1, 0, 3],\n",
       "  [1, 4, 1, 1, 2, 3, 3, 3, 3],\n",
       "  [1, 10, 7, 1, 0, 0, 1, 1, 14],\n",
       "  [0, 2, 0, 0, 1, 0, 2, 6, 4],\n",
       "  [1, 6, 0, 0, 2, 0, 1, 0, 7],\n",
       "  [1, 8, 3, 0, 1, 2, 3, 0, 4],\n",
       "  [1, 6, 4, 2, 0, 1, 1, 3, 2],\n",
       "  [0, 8, 1, 0, 1, 0, 0, 1, 10],\n",
       "  [1, 7, 2, 3, 1, 1, 0, 0, 1],\n",
       "  [1, 4, 3, 0, 2, 0, 2, 0, 4],\n",
       "  [1, 2, 0, 1, 0, 2, 1, 0, 9],\n",
       "  [1, 6, 2, 3, 0, 2, 0, 4, 2]],\n",
       " [[1, 3, 2, 1, 0, 2, 1, 0, 6],\n",
       "  [0, 6, 3, 2, 1, 1, 1, 1, 3],\n",
       "  [0, 1, 7, 3, 0, 7, 1, 0, 2],\n",
       "  [1, 3, 2, 2, 1, 0, 2, 2, 8],\n",
       "  [1, 6, 0, 3, 0, 2, 1, 2, 4],\n",
       "  [1, 11, 2, 0, 0, 16, 1, 1, 12],\n",
       "  [1, 6, 0, 0, 2, 0, 1, 0, 8],\n",
       "  [1, 19, 5, 8, 0, 7, 1, 0, 20],\n",
       "  [1, 4, 2, 1, 1, 1, 1, 1, 4],\n",
       "  [1, 9, 1, 3, 0, 2, 1, 4, 2],\n",
       "  [0, 5, 3, 5, 2, 1, 2, 1, 0],\n",
       "  [1, 7, 2, 1, 2, 1, 2, 0, 2],\n",
       "  [1, 6, 2, 5, 1, 3, 3, 1, 10],\n",
       "  [1, 10, 12, 0, 0, 2, 2, 0, 11],\n",
       "  [1, 19, 5, 7, 4, 8, 8, 3, 9],\n",
       "  [1, 6, 1, 0, 3, 1, 0, 4, 4],\n",
       "  [1, 8, 0, 4, 8, 0, 7, 2, 13],\n",
       "  [0, 24, 4, 2, 1, 0, 0, 1, 11],\n",
       "  [1, 5, 4, 2, 0, 3, 3, 3, 3],\n",
       "  [1, 2, 4, 1, 3, 1, 1, 2, 1],\n",
       "  [1, 12, 4, 3, 3, 4, 2, 6, 8],\n",
       "  [0, 9, 2, 6, 4, 0, 4, 2, 9],\n",
       "  [0, 8, 4, 2, 1, 2, 2, 3, 5],\n",
       "  [1, 6, 4, 1, 2, 0, 0, 0, 5],\n",
       "  [1, 6, 3, 0, 1, 2, 3, 0, 0],\n",
       "  [0, 1, 1, 1, 4, 0, 0, 0, 21],\n",
       "  [1, 4, 1, 2, 1, 2, 1, 0, 7],\n",
       "  [0, 6, 6, 5, 6, 3, 5, 4, 7],\n",
       "  [0, 6, 2, 1, 1, 1, 2, 0, 2],\n",
       "  [1, 10, 3, 8, 3, 5, 6, 12, 4],\n",
       "  [1, 11, 0, 0, 0, 3, 3, 2, 18],\n",
       "  [0, 2, 3, 2, 1, 4, 2, 0, 1],\n",
       "  [1, 9, 2, 1, 1, 3, 3, 2, 2],\n",
       "  [1, 2, 2, 5, 1, 1, 0, 3, 5],\n",
       "  [1, 6, 0, 1, 0, 4, 2, 5, 12],\n",
       "  [0, 9, 4, 5, 1, 3, 1, 0, 2],\n",
       "  [1, 7, 2, 2, 3, 2, 2, 3, 2],\n",
       "  [0, 1, 10, 1, 1, 7, 1, 3, 2],\n",
       "  [0, 12, 2, 0, 0, 3, 0, 0, 1],\n",
       "  [0, 17, 4, 5, 3, 1, 2, 2, 14],\n",
       "  [1, 11, 3, 0, 0, 1, 0, 0, 0],\n",
       "  [1, 20, 3, 5, 2, 5, 5, 7, 4],\n",
       "  [0, 7, 10, 2, 0, 22, 0, 0, 1],\n",
       "  [1, 5, 2, 1, 0, 1, 2, 0, 4],\n",
       "  [0, 6, 10, 8, 1, 10, 0, 0, 19],\n",
       "  [0, 7, 7, 6, 3, 6, 3, 4, 1],\n",
       "  [0, 86, 17, 8, 3, 20, 6, 6, 182],\n",
       "  [0, 6, 3, 3, 4, 6, 1, 2, 4],\n",
       "  [0, 2, 4, 2, 0, 1, 0, 0, 6],\n",
       "  [0, 4, 2, 5, 0, 1, 1, 0, 7],\n",
       "  [0, 10, 9, 0, 0, 2, 0, 4, 18],\n",
       "  [0, 6, 1, 0, 0, 3, 0, 0, 11]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seperated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".naiveBayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1ac89389d320b6dcbac69a2b7cff7705e510a760dbc8a2012424bf08459df72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
